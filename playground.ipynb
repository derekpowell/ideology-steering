{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2724c7b6-3913-4e88-b25b-94e840895c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/dmpowell/.cache/huggingface\n",
      "/scratch/dmpowell/.cache/huggingface/datasets\n",
      "device =  cuda\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------------------------\n",
    "## set up configs for huggingface hub and OS paths on HPC cluster -- make sure config.ini is correct\n",
    "## ---------------------------------------------------------------------\n",
    "import configparser\n",
    "\n",
    "def scratch_path():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(\"config.ini\")\n",
    "    return \"/scratch/\" + config[\"user\"][\"username\"]\n",
    "\n",
    "import os\n",
    "if os.path.isdir(scratch_path()):\n",
    "    os.environ['TRANSFORMERS_CACHE'] = scratch_path() + '/.cache/huggingface'\n",
    "    os.environ['HF_DATASETS_CACHE'] = scratch_path() + '/.cache/huggingface/datasets'\n",
    "print(os.getenv('TRANSFORMERS_CACHE'))\n",
    "print(os.getenv('HF_DATASETS_CACHE'))\n",
    "\n",
    "## ---------------------------------------------------------------------\n",
    "## Load libraries\n",
    "## ---------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, LlamaForCausalLM, LlamaTokenizer, AutoModelForCausalLM\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from baukit import Trace\n",
    "\n",
    "from steering import *\n",
    "## ---------------------------------------------------------------------\n",
    "## Ensure GPU is available -- device should == 'cuda'\n",
    "## ---------------------------------------------------------------------\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device = \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "de83defa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5326df908c46c5bbbeea5d9d771655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59efb22283f4a1c95c27370b927783c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "# MODEL_NAME = \"meta-llama/Llama-3.1-8B\"\n",
    "\n",
    "wmodel = SteeringModel(\n",
    "    AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,  # Replace this with the 70B variant if available\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=device  # Automatically distributes the model across available GPUs\n",
    "    ),\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, device = 'cuda', use_fast = False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5cb158",
   "metadata": {},
   "source": [
    "## Multiple choice\n",
    "\n",
    "Here is a basic implementation of multiple choice answering using \"cloze\" probabilities. This should roughly work with both raw and instruction-tuned models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "473a7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def answer_choice_list(choices):\n",
    "    options = re.split(r'\\s*\\(\\w\\)\\s*', choices)\n",
    "    return( [option.strip() for option in options if option] )\n",
    "\n",
    "\n",
    "def format_question(question):\n",
    "    return f\"Q: {question}\\nA:\"\n",
    "\n",
    "\n",
    "# def format_statement(question, choices):\n",
    "#     choice_string = \", \".join(choices)\n",
    "#     return f\"Please rate your agreement with the following statement, using the following scale: [{choice_string}]. Statement: {question}\\nResponse:\"\n",
    "\n",
    "\n",
    "def format_with_instructions(instruction, question, choices):\n",
    "    # choice_string = \"; \".join(choices)\n",
    "    return f\"{instruction} Specifically, please use the following response options: {choices}.\\n\\nStatement: {question}\\nResponse:\"\n",
    "\n",
    "\n",
    "def format_with_mcqa_instructions(instruction, question, choices_text):\n",
    "    \n",
    "    LETTERS = [chr(i) for i in range(65,91)]\n",
    "    choices = re.split(';\\W', choices_text)\n",
    "    choices = [c.strip() for c in choices]\n",
    "    labeled_choices = [\". \".join([a,b]) for a, b in zip(LETTERS, choices)]\n",
    "    labeled_choices = \"\\n\".join(labeled_choices)\n",
    "    \n",
    "    return f\"{instruction} Respond with the letter corresponding to your choice from the following response options:\\n\\n{labeled_choices}\\n\\nStatement: {question}\\nResponse:\"\n",
    "\n",
    "\n",
    "def format_chat_question(instruction, question, choices):\n",
    "    return f\"{instruction} Specifically, please use the following response options: {choices}.\\n\\nStatement: {question}\"\n",
    "\n",
    "\n",
    "def format_mcqa_chat_question(instruction, question, choices_text):\n",
    "    \n",
    "    LETTERS = [chr(i) for i in range(65,91)]\n",
    "    choices = re.split(';\\W', choices_text)\n",
    "    choices = [c.strip() for c in choices]\n",
    "    labeled_choices = [\". \".join([a,b]) for a, b in zip(LETTERS, choices)]\n",
    "    labeled_choices = \"\\n\".join(labeled_choices)\n",
    "    \n",
    "    return f\"{instruction} Respond with the letter corresponding to your choice from the following response options:\\n\\n{labeled_choices}\\n\\nStatement: {question}\"\n",
    "\n",
    "\n",
    "def format_chat(instruction, question, choices):\n",
    "\n",
    "    chat = [\n",
    "        {\"role\": \"user\", \"content\": format_chat_question(instruction, question, choices)},\n",
    "        {\"role\": \"system\", \"content\": \"My Response:\"}\n",
    "    ]\n",
    "\n",
    "    tokens = wmodel.tok.apply_chat_template(chat, tokenize=True, continue_final_message=True)[:-1]\n",
    "\n",
    "    return(wmodel.tok.decode(tokens))\n",
    "\n",
    "\n",
    "def format_mcqa_chat(instruction, question, choices):\n",
    "\n",
    "    chat = [\n",
    "        {\"role\": \"user\", \"content\": format_mcqa_chat_question(instruction, question, choices)},\n",
    "        {\"role\": \"system\", \"content\": \"My Response:\"}\n",
    "    ]\n",
    "\n",
    "    tokens = wmodel.tok.apply_chat_template(chat, tokenize=True, continue_final_message=True)[:-1]\n",
    "\n",
    "    return(wmodel.tok.decode(tokens))\n",
    "\n",
    "\n",
    "def mc_choice_probs(model, question, choices, pad = True):\n",
    "    prompt = question\n",
    "    if pad:\n",
    "        choices = [\" \" + c for c in choices] # pad all the \n",
    "    \n",
    "    prompts = [prompt for c in choices]\n",
    "    \n",
    "    logits = torch.tensor([model.completion_logprob(x[0], x[1]) for x in zip(prompts, choices)])\n",
    "    \n",
    "    return(F.log_softmax(logits, -1).exp())\n",
    "\n",
    "\n",
    "def choice_score(choice_probs):\n",
    "    # calculate score on -1 to 1 scale\n",
    "    choice_score01 = choice_probs @ torch.arange(len(choice_probs), dtype = choice_probs.dtype)/(len(choice_probs)-1)\n",
    "    return (choice_score01.item() - .5)*2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7806dfd9",
   "metadata": {},
   "source": [
    "For any agree/disagree etc. style scales, we can take the choice probabilities and compute a \"score\". I noticed the model seems to have a really strong \"agree\" bias when we have a pure \"agree\" option. Will need to look into this, probably some literature on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ecca48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5542304217815399, tensor([0.7577, 0.0141, 0.0009, 0.0336, 0.1937]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choice_text = ['Strongly disagree', 'Somewhat disagree', \"Neither agree nor disagree\", 'Somewhat agree', 'Strongly agree']\n",
    "# q = format_question('Slavery benefitted the slaves, many of whom learned valuable skills.')\n",
    "q = format_statement('Slavery benefitted the slaves, many of whom learned valuable skills.', choice_text)\n",
    "choice_probs = mc_choice_probs(wmodel, q, choice_text )\n",
    "choice_score(choice_probs), choice_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0229b7e",
   "metadata": {},
   "source": [
    "## Steering\n",
    "\n",
    "Applying a steering vector shifts generations ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "99a54164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In my opinion, dogs are the best companions you can have. They are always happy to see you, they love to play']\n",
      "--------------------\n",
      "['In my opinion, dogs are one of the most wonderful creatures on this planet. They are a symbol of love, loyalty,']\n",
      "--------------------\n",
      "[\"In my opinion, dogs are the worst creatures on the planet. They're always whining, they're always shitting,\"]\n"
     ]
    }
   ],
   "source": [
    "def get_mean_steering_vector(ziplist, model):\n",
    "    return torch.concat([model.get_steering_vector(s1, s2) for s1, s2 in ziplist]).mean(0).unsqueeze(0)\n",
    "\n",
    "\n",
    "def act_add(steering_vec):\n",
    "    def act_add(output):\n",
    "        z = torch.ones_like(output[0])\n",
    "        z = z * steering_vec\n",
    "        out = output[0] + z\n",
    "        return (out, output[1])\n",
    "    return act_add\n",
    "\n",
    "\n",
    "steering_vec = get_mean_steering_vector([[\"Love\", \"Hate\"], [\"Beautiful\", \"Disgusting\"], [\"Loving\", \"Hateful\"]], wmodel)\n",
    "\n",
    "test_sentence = \"In my opinion, dogs\"\n",
    "\n",
    "print(wmodel.generate(test_sentence, max_new_tokens = 20))\n",
    "print(\"-\"*20)\n",
    "with Trace(wmodel.get_module(), edit_output = act_add(steering_vec)):\n",
    "    print(wmodel.generate(test_sentence, max_new_tokens = 20))\n",
    "print(\"-\"*20)\n",
    "with Trace(wmodel.get_module(), edit_output = act_add(-1.5*steering_vec)):\n",
    "    print(wmodel.generate(test_sentence, max_new_tokens = 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc77d7fe",
   "metadata": {},
   "source": [
    "### \"survey\" responses and attitude scores\n",
    "\n",
    "Can apply the same thing to our multiple choice decisions and calculated scores. Adding a relevant steering vector affects the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bd318be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0900799036026001 tensor([0.4413, 0.0123, 0.0035, 0.0108, 0.5321])\n",
      "-0.8198438286781311 tensor([0.9074, 0.0010, 0.0026, 0.0018, 0.0872])\n"
     ]
    }
   ],
   "source": [
    "steering_vec = wmodel.get_steering_vector(\"Slavery is a proud part of American history.\", \"Slavery is the most shameful part of America's past.\")\n",
    "\n",
    "# steering_vec = get_mean_steering_vector([[\"Some races are inferior to others.\", \"No race is inferior to others.\"], [\"White people are superior to black people.\", \"White and black people are equally good.\"]], wmodel)\n",
    "\n",
    "# q = format_question('Slavery benefitted the slaves, many of whom learned valuable skills.')\n",
    "q = format_statement('Slavery benefitted the slaves, many of whom learned valuable skills.', choice_text)\n",
    "\n",
    "with Trace(wmodel.get_module(), edit_output = act_add(steering_vec)):\n",
    "    # print(wmodel.generate(test_sentence, max_new_tokens = 20))\n",
    "    choice_probs = mc_choice_probs(wmodel, format_question('Slavery benefitted the slaves who learned valuable skills.'), ['Strongly disagree',  'Somewhat disagree', \"Neither agree nor disagree\", 'Somewhat agree', 'Strongly agree'])\n",
    "    print(choice_score(choice_probs), choice_probs) \n",
    "\n",
    "with Trace(wmodel.get_module(), edit_output = act_add(-steering_vec)):\n",
    "    # print(wmodel.generate(test_sentence, max_new_tokens = 20))\n",
    "    choice_probs = mc_choice_probs(wmodel, format_question('Slavery benefitted the slaves who learned valuable skills.'), ['Strongly disagree',  'Somewhat disagree', \"Neither agree nor disagree\", 'Somewhat agree', 'Strongly agree'])\n",
    "    print(choice_score(choice_probs), choice_probs) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed5efa7",
   "metadata": {},
   "source": [
    "## Applying to survey ideology scales\n",
    "\n",
    "First, to generate the model's answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "32ecfb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = pd.read_csv(\"data/scales.tsv\", sep=\"\\t\")\n",
    "\n",
    "scales = scales.loc[lambda x: x.sub_scale != 'not scored']\n",
    "scales['resposne_options'] = [re.sub(r\"\\s*\\(.*?\\)\\s*\", \" \", text).strip() for text in scales['response_options']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8cdb383c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[176], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m MODEL_NAME\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-3.1-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     25\u001b[0m         q \u001b[38;5;241m=\u001b[39m format_chat(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstruction\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse_options\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 27\u001b[0m choice_probs \u001b[38;5;241m=\u001b[39m mc_choice_probs(wmodel, q, choices) \u001b[38;5;66;03m# format_chat for instruct model\u001b[39;00m\n\u001b[1;32m     29\u001b[0m resp_probs\u001b[38;5;241m.\u001b[39mappend(choice_probs\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     30\u001b[0m resps\u001b[38;5;241m.\u001b[39mappend(choice_score(choice_probs) \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirection\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39mchoice_score(choice_probs))\n",
      "Cell \u001b[0;32mIn[116], line 79\u001b[0m, in \u001b[0;36mmc_choice_probs\u001b[0;34m(model, question, choices, pad)\u001b[0m\n\u001b[1;32m     75\u001b[0m     choices \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m choices] \u001b[38;5;66;03m# pad all the \u001b[39;00m\n\u001b[1;32m     77\u001b[0m prompts \u001b[38;5;241m=\u001b[39m [prompt \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m choices]\n\u001b[0;32m---> 79\u001b[0m logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([model\u001b[38;5;241m.\u001b[39mcompletion_logprob(x[\u001b[38;5;241m0\u001b[39m], x[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(prompts, choices)])\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(F\u001b[38;5;241m.\u001b[39mlog_softmax(logits, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexp())\n",
      "Cell \u001b[0;32mIn[116], line 79\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m     choices \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m choices] \u001b[38;5;66;03m# pad all the \u001b[39;00m\n\u001b[1;32m     77\u001b[0m prompts \u001b[38;5;241m=\u001b[39m [prompt \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m choices]\n\u001b[0;32m---> 79\u001b[0m logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([model\u001b[38;5;241m.\u001b[39mcompletion_logprob(x[\u001b[38;5;241m0\u001b[39m], x[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(prompts, choices)])\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(F\u001b[38;5;241m.\u001b[39mlog_softmax(logits, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexp())\n",
      "File \u001b[0;32m~/work/ideology-steering/steering/steering.py:93\u001b[0m, in \u001b[0;36mSteeringModel.completion_logprob\u001b[0;34m(self, prefix, suffix, summed)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompletion_logprob\u001b[39m(\u001b[38;5;28mself\u001b[39m, prefix, suffix, summed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     92\u001b[0m     full_text \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m suffix\n\u001b[0;32m---> 93\u001b[0m     full \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_logprobs(full_text)\n\u001b[1;32m     94\u001b[0m     pre_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtok(prefix)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     95\u001b[0m     res \u001b[38;5;241m=\u001b[39m full[(pre_len\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m summed \u001b[38;5;28;01melse\u001b[39;00m full[(pre_len\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):]\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/work/ideology-steering/steering/steering.py:85\u001b[0m, in \u001b[0;36mSteeringModel.obs_logprobs\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobs_logprobs\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m---> 85\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_logits(text)\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [F\u001b[38;5;241m.\u001b[39mlog_softmax(l, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m logits] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(logits)\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mlist\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlog_softmax(logits, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/work/ideology-steering/steering/steering.py:64\u001b[0m, in \u001b[0;36mSteeringModel.obs_logits\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobs_logits\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m---> 64\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogits(text)\n\u001b[1;32m     65\u001b[0m     logits \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     67\u001b[0m     obslogits \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/work/ideology-steering/steering/steering.py:49\u001b[0m, in \u001b[0;36mSteeringModel.logits\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# texts = self.preprompt + texts if type(texts)==str else [self.preprompt + t for t in texts]\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# encoding = self.tok(texts, padding=True, return_tensors='pt').to(self.model.device)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 49\u001b[0m     model_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(encoding[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     50\u001b[0m     logits \u001b[38;5;241m=\u001b[39m model_out\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: encoding, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m: logits}\n",
      "File \u001b[0;32m~/.conda/envs/py3.11transformers4.44/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/py3.11transformers4.44/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py3.11transformers4.44/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:1189\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1186\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1190\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1191\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1192\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1193\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1194\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1195\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1196\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1197\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1198\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1199\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m   1200\u001b[0m )\n\u001b[1;32m   1202\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/py3.11transformers4.44/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/py3.11transformers4.44/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py3.11transformers4.44/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:1001\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    989\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    990\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    991\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    998\u001b[0m         position_embeddings,\n\u001b[1;32m    999\u001b[0m     )\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1001\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[1;32m   1002\u001b[0m         hidden_states,\n\u001b[1;32m   1003\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask,\n\u001b[1;32m   1004\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1005\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1006\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1007\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1008\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m   1009\u001b[0m         position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[1;32m   1010\u001b[0m     )\n\u001b[1;32m   1012\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.conda/envs/py3.11transformers4.44/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/py3.11transformers4.44/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py3.11transformers4.44/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    733\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    735\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    736\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    737\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m    738\u001b[0m     past_key_value\u001b[38;5;241m=\u001b[39mpast_key_value,\n\u001b[1;32m    739\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    740\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    741\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m    742\u001b[0m     position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    744\u001b[0m )\n\u001b[1;32m    745\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py3.11transformers4.44/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/py3.11transformers4.44/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py3.11transformers4.44/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:621\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\n\u001b[1;32m    619\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\n\u001b[0;32m--> 621\u001b[0m query_states \u001b[38;5;241m=\u001b[39m query_states\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    622\u001b[0m key_states \u001b[38;5;241m=\u001b[39m key_states\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    623\u001b[0m value_states \u001b[38;5;241m=\u001b[39m value_states\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Getting model responses\n",
    "MCQA = True\n",
    "resps = []\n",
    "resp_probs = []\n",
    "\n",
    "for idx, row in scales.iterrows():\n",
    "\n",
    "    if MCQA:\n",
    "        LETTERS = [chr(i) for i in range(65,91)]\n",
    "        choices = re.split(';\\W', row['response_options'])\n",
    "        choices = LETTERS[:len(choices)]\n",
    "        \n",
    "        if MODEL_NAME==\"meta-llama/Llama-3.1-8B\":\n",
    "            q = format_with_mcqa_instructions(row['instruction'], row['question'], row['response_options'])\n",
    "        elif MODEL_NAME==\"meta-llama/Llama-3.1-8B-Instruct\":\n",
    "            q = format_mcqa_chat(row['instruction'], row['question'], row['response_options'])\n",
    "    \n",
    "    else:\n",
    "        choices = re.split(';\\W', row['response_options'])\n",
    "        choices = [c.strip() for c in choices]\n",
    "\n",
    "        if MODEL_NAME==\"meta-llama/Llama-3.1-8B\":\n",
    "            q = format_with_instructions(row['instruction'], row['question'], row['response_options'])\n",
    "        elif MODEL_NAME==\"meta-llama/Llama-3.1-8B-Instruct\":\n",
    "            q = format_chat(row['instruction'], row['question'], row['response_options'])\n",
    "    \n",
    "    choice_probs = mc_choice_probs(wmodel, q, choices) # format_chat for instruct model\n",
    "\n",
    "    resp_probs.append(choice_probs.detach().numpy())\n",
    "    resps.append(choice_score(choice_probs) if row['direction']=='high' else -choice_score(choice_probs))\n",
    "    \n",
    "scales[\"response_probs\"] = resp_probs\n",
    "scales[\"model_score\"] = resps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "90cee6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Below are items that relate to the cultures of different parts of the world. Work quickly and record your first reaction to each item. There are no right or wrong answers. Please indicate the degree to which you agree or disagree with each item using the following five-point scale: Respond with the letter corresponding to your choice from the following response options:\n",
      "\n",
      "A. (1) Strongly disagree\n",
      "B. (2) Disagree\n",
      "C. (3) Neutral\n",
      "D. (4) Agree\n",
      "E. (5) Strongly agree\n",
      "\n",
      "Statement: People from other cultures act strange and unusual when they come into my culture.<|eot_id|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "My Response:\n",
      "tensor([0.1037, 0.7661, 0.0337, 0.0629, 0.0337])\n"
     ]
    }
   ],
   "source": [
    "print(q)\n",
    "print(choice_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "29e5646f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale</th>\n",
       "      <th>sub_scale</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">CSES</th>\n",
       "      <th>Importance to Identity</th>\n",
       "      <td>0.217570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Membership self-esteem.</th>\n",
       "      <td>0.218764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Private collective self-esteem</th>\n",
       "      <td>0.111093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Public collective self-esteem</th>\n",
       "      <td>0.152117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IPVAS</th>\n",
       "      <th>Control</th>\n",
       "      <td>-0.135758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Threat</th>\n",
       "      <td>-0.337151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Violence</th>\n",
       "      <td>-0.583751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">LWAI</th>\n",
       "      <th>Anticonventionalism</th>\n",
       "      <td>-0.256659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Antihierarchical Aggression</th>\n",
       "      <td>-0.364906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top-Down Censorship</th>\n",
       "      <td>-0.007525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MFQ</th>\n",
       "      <th>Authority</th>\n",
       "      <td>0.072525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairness</th>\n",
       "      <td>0.600666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harm</th>\n",
       "      <td>0.559139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ingroup</th>\n",
       "      <td>0.172293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purity</th>\n",
       "      <td>-0.009540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not scored</th>\n",
       "      <td>-0.083115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PECS</th>\n",
       "      <th>Conservative</th>\n",
       "      <td>0.196789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liberal</th>\n",
       "      <td>-0.426702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SDO-7</th>\n",
       "      <th>antiegalitarianism</th>\n",
       "      <td>-0.426584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dominance</th>\n",
       "      <td>-0.459144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      avg_score\n",
       "scale sub_scale                                \n",
       "CSES  Importance to Identity           0.217570\n",
       "      Membership self-esteem.          0.218764\n",
       "      Private collective self-esteem   0.111093\n",
       "      Public collective self-esteem    0.152117\n",
       "IPVAS Control                         -0.135758\n",
       "      Threat                          -0.337151\n",
       "      Violence                        -0.583751\n",
       "LWAI  Anticonventionalism             -0.256659\n",
       "      Antihierarchical Aggression     -0.364906\n",
       "      Top-Down Censorship             -0.007525\n",
       "MFQ   Authority                        0.072525\n",
       "      Fairness                         0.600666\n",
       "      Harm                             0.559139\n",
       "      Ingroup                          0.172293\n",
       "      Purity                          -0.009540\n",
       "      not scored                      -0.083115\n",
       "PECS  Conservative                     0.196789\n",
       "      Liberal                         -0.426702\n",
       "SDO-7 antiegalitarianism              -0.426584\n",
       "      dominance                       -0.459144"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer_choice_list('Strongly disagree, Somewhat disagree, Neither agree nor disagree, Somewhat agree, Strongly agree')\n",
    "\n",
    "scales.groupby(['scale', 'sub_scale']).agg(avg_score = ('model_score', 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "207754ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>scale</th>\n",
       "      <th>response_options</th>\n",
       "      <th>response_probs</th>\n",
       "      <th>model_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>A child should learn early in life the value o...</td>\n",
       "      <td>PECS</td>\n",
       "      <td>Strong opposition; Moderate opposition; Slight...</td>\n",
       "      <td>[0.0038007332, 0.0071007046, 0.0048802383, 0.0...</td>\n",
       "      <td>0.861297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Depressions are like occasional headaches and ...</td>\n",
       "      <td>PECS</td>\n",
       "      <td>Strong opposition; Moderate opposition; Slight...</td>\n",
       "      <td>[0.06870035, 0.18674694, 0.12834916, 0.1648036...</td>\n",
       "      <td>0.182027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Every adult should find time or money for some...</td>\n",
       "      <td>PECS</td>\n",
       "      <td>Strong opposition; Moderate opposition; Slight...</td>\n",
       "      <td>[0.0060474244, 0.02710267, 0.018627374, 0.0736...</td>\n",
       "      <td>0.731179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>The businessman, the manufacturer, the practic...</td>\n",
       "      <td>PECS</td>\n",
       "      <td>Strong opposition; Moderate opposition; Slight...</td>\n",
       "      <td>[0.5610595, 0.3403001, 0.0217547, 0.019198474,...</td>\n",
       "      <td>-0.710264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>The best way to solve social problems is to st...</td>\n",
       "      <td>PECS</td>\n",
       "      <td>Strong opposition; Moderate opposition; Slight...</td>\n",
       "      <td>[0.09297201, 0.28637424, 0.13527347, 0.1352734...</td>\n",
       "      <td>0.006581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>A political candidate, to be worth voting for,...</td>\n",
       "      <td>PECS</td>\n",
       "      <td>Strong opposition; Moderate opposition; Slight...</td>\n",
       "      <td>[0.04173877, 0.10012592, 0.053593643, 0.100125...</td>\n",
       "      <td>0.488544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Young people sometimes get rebellious ideas, b...</td>\n",
       "      <td>PECS</td>\n",
       "      <td>Strong opposition; Moderate opposition; Slight...</td>\n",
       "      <td>[0.033851378, 0.2834341, 0.17191146, 0.1719114...</td>\n",
       "      <td>0.046684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>It is the responsibility of the entire society...</td>\n",
       "      <td>PECS</td>\n",
       "      <td>Strong opposition; Moderate opposition; Slight...</td>\n",
       "      <td>[0.005076593, 0.015637007, 0.010747148, 0.0545...</td>\n",
       "      <td>-0.725476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>The only way to provide adequate medical care ...</td>\n",
       "      <td>PECS</td>\n",
       "      <td>Strong opposition; Moderate opposition; Slight...</td>\n",
       "      <td>[0.11816126, 0.22075406, 0.055815425, 0.071668...</td>\n",
       "      <td>-0.186099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>It is essential after the war to maintain or i...</td>\n",
       "      <td>PECS</td>\n",
       "      <td>Strong opposition; Moderate opposition; Slight...</td>\n",
       "      <td>[0.013381446, 0.09887625, 0.036374543, 0.11204...</td>\n",
       "      <td>-0.480899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>In general, full economic security is harmful;...</td>\n",
       "      <td>PECS</td>\n",
       "      <td>Strong opposition; Moderate opposition; Slight...</td>\n",
       "      <td>[0.48810226, 0.33546746, 0.040065873, 0.040065...</td>\n",
       "      <td>-0.601662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>It is a fundamental American tradition that th...</td>\n",
       "      <td>PECS</td>\n",
       "      <td>Strong opposition; Moderate opposition; Slight...</td>\n",
       "      <td>[0.14042144, 0.23151581, 0.07516218, 0.0965101...</td>\n",
       "      <td>0.117682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Labor unions should become stronger by being p...</td>\n",
       "      <td>PECS</td>\n",
       "      <td>Strong opposition; Moderate opposition; Slight...</td>\n",
       "      <td>[0.0028747064, 0.007814262, 0.005370659, 0.030...</td>\n",
       "      <td>-0.817670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Whether one likes them or not, one has to admi...</td>\n",
       "      <td>PECS</td>\n",
       "      <td>Strong opposition; Moderate opposition; Slight...</td>\n",
       "      <td>[0.036619, 0.1448311, 0.0775225, 0.127813, 0.3...</td>\n",
       "      <td>0.377112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>The government must play an even greater part ...</td>\n",
       "      <td>PECS</td>\n",
       "      <td>Strong opposition; Moderate opposition; Slight...</td>\n",
       "      <td>[0.20808071, 0.30275565, 0.059616122, 0.067553...</td>\n",
       "      <td>0.076636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Character, honesty, and ability will tell in t...</td>\n",
       "      <td>PECS</td>\n",
       "      <td>Strong opposition; Moderate opposition; Slight...</td>\n",
       "      <td>[0.0074949195, 0.038062334, 0.026159832, 0.103...</td>\n",
       "      <td>0.665497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question scale  \\\n",
       "232  A child should learn early in life the value o...  PECS   \n",
       "233  Depressions are like occasional headaches and ...  PECS   \n",
       "234  Every adult should find time or money for some...  PECS   \n",
       "235  The businessman, the manufacturer, the practic...  PECS   \n",
       "236  The best way to solve social problems is to st...  PECS   \n",
       "237  A political candidate, to be worth voting for,...  PECS   \n",
       "238  Young people sometimes get rebellious ideas, b...  PECS   \n",
       "239  It is the responsibility of the entire society...  PECS   \n",
       "240  The only way to provide adequate medical care ...  PECS   \n",
       "241  It is essential after the war to maintain or i...  PECS   \n",
       "242  In general, full economic security is harmful;...  PECS   \n",
       "243  It is a fundamental American tradition that th...  PECS   \n",
       "244  Labor unions should become stronger by being p...  PECS   \n",
       "245  Whether one likes them or not, one has to admi...  PECS   \n",
       "246  The government must play an even greater part ...  PECS   \n",
       "247  Character, honesty, and ability will tell in t...  PECS   \n",
       "\n",
       "                                      response_options  \\\n",
       "232  Strong opposition; Moderate opposition; Slight...   \n",
       "233  Strong opposition; Moderate opposition; Slight...   \n",
       "234  Strong opposition; Moderate opposition; Slight...   \n",
       "235  Strong opposition; Moderate opposition; Slight...   \n",
       "236  Strong opposition; Moderate opposition; Slight...   \n",
       "237  Strong opposition; Moderate opposition; Slight...   \n",
       "238  Strong opposition; Moderate opposition; Slight...   \n",
       "239  Strong opposition; Moderate opposition; Slight...   \n",
       "240  Strong opposition; Moderate opposition; Slight...   \n",
       "241  Strong opposition; Moderate opposition; Slight...   \n",
       "242  Strong opposition; Moderate opposition; Slight...   \n",
       "243  Strong opposition; Moderate opposition; Slight...   \n",
       "244  Strong opposition; Moderate opposition; Slight...   \n",
       "245  Strong opposition; Moderate opposition; Slight...   \n",
       "246  Strong opposition; Moderate opposition; Slight...   \n",
       "247  Strong opposition; Moderate opposition; Slight...   \n",
       "\n",
       "                                        response_probs  model_score  \n",
       "232  [0.0038007332, 0.0071007046, 0.0048802383, 0.0...     0.861297  \n",
       "233  [0.06870035, 0.18674694, 0.12834916, 0.1648036...     0.182027  \n",
       "234  [0.0060474244, 0.02710267, 0.018627374, 0.0736...     0.731179  \n",
       "235  [0.5610595, 0.3403001, 0.0217547, 0.019198474,...    -0.710264  \n",
       "236  [0.09297201, 0.28637424, 0.13527347, 0.1352734...     0.006581  \n",
       "237  [0.04173877, 0.10012592, 0.053593643, 0.100125...     0.488544  \n",
       "238  [0.033851378, 0.2834341, 0.17191146, 0.1719114...     0.046684  \n",
       "239  [0.005076593, 0.015637007, 0.010747148, 0.0545...    -0.725476  \n",
       "240  [0.11816126, 0.22075406, 0.055815425, 0.071668...    -0.186099  \n",
       "241  [0.013381446, 0.09887625, 0.036374543, 0.11204...    -0.480899  \n",
       "242  [0.48810226, 0.33546746, 0.040065873, 0.040065...    -0.601662  \n",
       "243  [0.14042144, 0.23151581, 0.07516218, 0.0965101...     0.117682  \n",
       "244  [0.0028747064, 0.007814262, 0.005370659, 0.030...    -0.817670  \n",
       "245  [0.036619, 0.1448311, 0.0775225, 0.127813, 0.3...     0.377112  \n",
       "246  [0.20808071, 0.30275565, 0.059616122, 0.067553...     0.076636  \n",
       "247  [0.0074949195, 0.038062334, 0.026159832, 0.103...     0.665497  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scales.loc[lambda x: x.scale==\"PECS\"][['question','scale', 'response_options', 'response_probs', 'model_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa29a038",
   "metadata": {},
   "source": [
    "## quick steering test\n",
    "\n",
    "### On the instruct model\n",
    "\n",
    "- model steering with a subset of SDO items does affect SDO -- so that's promising! it does immediately pass a really basic/naive test.\n",
    "- AND, it also spills over to substantailly affect IPVAS, suggesting some generalization.\n",
    "\n",
    "\n",
    "### on the non-instruct model\n",
    "\n",
    "- seemingly it is not affected, which is strange. Also scores very strangely in raw tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "57c1c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdo = scales.loc[lambda x: ((x.scale == \"SDO-7\") & (x.direction == 'high'))]\n",
    "# sdo_zipped = zip(sdo.original_statement.to_list(), sdo.contrastive_statement.to_list())\n",
    "# sdo_vec = get_mean_steering_vector(sdo_zipped, wmodel)\n",
    "\n",
    "# ## Getting model responses\n",
    "\n",
    "# resps = []\n",
    "# resp_probs = []\n",
    "\n",
    "# for idx, row in scales.iterrows():\n",
    "\n",
    "#     with Trace(wmodel.get_module(), edit_output = act_add(2*steering_vec)):\n",
    "#         choices = re.split(';\\W', row['response'])\n",
    "#         choices = [c.strip() for c in choices]\n",
    "#         choice_probs = mc_choice_probs(wmodel, format_chat(row['original_statement']), choices) # format_chat for instruct model\n",
    "\n",
    "#         resp_probs.append(choice_probs.detach().numpy())\n",
    "#         resps.append(choice_score(choice_probs) if row['direction']=='high' else -choice_score(choice_probs))\n",
    "    \n",
    "# scales[\"response_probs\"] = resp_probs\n",
    "# scales[\"model_score\"] = resps\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5b88e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdo = scales.loc[lambda x: ((x.scale == \"SJS\") & (x.direction == 'high'))]\n",
    "# sdo_zipped = zip(sdo.statement.to_list(), sdo.simple_contrastive_statement.to_list())\n",
    "# steering_vec = get_mean_steering_vector(sdo_zipped, wmodel)\n",
    "\n",
    "\n",
    "## Getting model responses\n",
    "MCQA = False\n",
    "resps = []\n",
    "resp_probs = []\n",
    "resps_posvec = []\n",
    "resp_probs_posvec = []\n",
    "resps_negvec = []\n",
    "resp_probs_negvec = []\n",
    "\n",
    "curr_subscale = \"\"\n",
    "\n",
    "for idx, row in scales.iterrows():\n",
    "    if row['sub_scale'] != curr_subscale:\n",
    "        curr_subscale = row['sub_scale']\n",
    "        items = scales.loc[lambda x: ((x.sub_scale == curr_subscale) & (x.direction == 'high'))]\n",
    "        if len(items) == 0:\n",
    "            items = scales.loc[lambda x: ((x.sub_scale == curr_subscale) & (x.direction == 'low'))]\n",
    "            items_zipped = zip(items.simple_contrastive_statement.to_list(), items.statement.to_list())\n",
    "        else:\n",
    "            items_zipped = zip(items.statement.to_list(), items.simple_contrastive_statement.to_list())\n",
    "        \n",
    "        steering_vec = get_mean_steering_vector(items_zipped, wmodel)\n",
    "\n",
    "    if MCQA:\n",
    "        LETTERS = [chr(i) for i in range(65,91)]\n",
    "        choices = re.split(';\\W', row['response_options'])\n",
    "        choices = LETTERS[:len(choices)]\n",
    "        \n",
    "        if MODEL_NAME==\"meta-llama/Llama-3.1-8B\":\n",
    "            q = format_with_mcqa_instructions(row['instruction'], row['question'], row['response_options'])\n",
    "        elif MODEL_NAME==\"meta-llama/Llama-3.1-8B-Instruct\":\n",
    "            q = format_mcqa_chat(row['instruction'], row['question'], row['response_options'])\n",
    "    \n",
    "    else:\n",
    "        choices = re.split(';\\W', row['response_options'])\n",
    "        choices = [c.strip() for c in choices]\n",
    "\n",
    "        if MODEL_NAME==\"meta-llama/Llama-3.1-8B\":\n",
    "            q = format_with_instructions(row['instruction'], row['question'], row['response_options'])\n",
    "        elif MODEL_NAME==\"meta-llama/Llama-3.1-8B-Instruct\":\n",
    "            q = format_chat(row['instruction'], row['question'], row['response_options'])\n",
    "\n",
    "    choice_probs = mc_choice_probs(wmodel, q, choices) # format_chat for instruct model\n",
    "\n",
    "    resp_probs.append(choice_probs.detach().numpy())\n",
    "    resps.append(choice_score(choice_probs) if row['direction']=='high' else -choice_score(choice_probs))\n",
    "    \n",
    "    with Trace(wmodel.get_module(), edit_output = act_add(steering_vec)):\n",
    "        choice_probs = mc_choice_probs(wmodel, q, choices) # format_chat for instruct model\n",
    "\n",
    "    resp_probs_posvec.append(choice_probs.detach().numpy())\n",
    "    resps_posvec.append(choice_score(choice_probs) if row['direction']=='high' else -choice_score(choice_probs))\n",
    "\n",
    "    with Trace(wmodel.get_module(), edit_output = act_add(-steering_vec)):\n",
    "        choice_probs = mc_choice_probs(wmodel, q, choices) # format_chat for instruct model\n",
    "\n",
    "    resp_probs_negvec.append(choice_probs.detach().numpy())\n",
    "    resps_negvec.append(choice_score(choice_probs) if row['direction']=='high' else -choice_score(choice_probs))\n",
    "    \n",
    "scales[\"response_probs\"] = resp_probs\n",
    "scales[\"model_score\"] = resps\n",
    "\n",
    "scales[\"response_probs_posvec\"] = resp_probs_posvec\n",
    "scales[\"model_score_posvec\"] = resps_posvec\n",
    "\n",
    "scales[\"response_probs_negvec\"] = resp_probs_negvec\n",
    "scales[\"model_score_negvec\"] = resps_negvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "99f26699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg_score</th>\n",
       "      <th>avg_pos</th>\n",
       "      <th>avg_neg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale</th>\n",
       "      <th>sub_scale</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">CSES</th>\n",
       "      <th>Importance to Identity</th>\n",
       "      <td>0.141718</td>\n",
       "      <td>-0.002377</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Membership self-esteem.</th>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>0.001528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Private collective self-esteem</th>\n",
       "      <td>0.240555</td>\n",
       "      <td>0.113424</td>\n",
       "      <td>-0.000769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Public collective self-esteem</th>\n",
       "      <td>0.067603</td>\n",
       "      <td>0.010602</td>\n",
       "      <td>-0.008052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVS</th>\n",
       "      <th>Capitalistic Values</th>\n",
       "      <td>-0.123596</td>\n",
       "      <td>-0.111300</td>\n",
       "      <td>-0.107416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GENE</th>\n",
       "      <th>Generalized Ethnocentrism</th>\n",
       "      <td>-0.162873</td>\n",
       "      <td>-0.139365</td>\n",
       "      <td>-0.059201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IPVAS</th>\n",
       "      <th>Control</th>\n",
       "      <td>-0.014541</td>\n",
       "      <td>-0.000717</td>\n",
       "      <td>-0.031385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Threat</th>\n",
       "      <td>0.119851</td>\n",
       "      <td>0.207797</td>\n",
       "      <td>-0.038988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Violence</th>\n",
       "      <td>-0.333352</td>\n",
       "      <td>-0.333357</td>\n",
       "      <td>-0.320668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JWS</th>\n",
       "      <th>Just World Belief</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>-0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">LWAI</th>\n",
       "      <th>Anticonventionalism</th>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.013732</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Antihierarchical Aggression</th>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top-Down Censorship</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">MFQ</th>\n",
       "      <th>Authority</th>\n",
       "      <td>0.498127</td>\n",
       "      <td>0.490220</td>\n",
       "      <td>0.448502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairness</th>\n",
       "      <td>0.836190</td>\n",
       "      <td>0.796198</td>\n",
       "      <td>0.768029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harm</th>\n",
       "      <td>0.848938</td>\n",
       "      <td>0.865632</td>\n",
       "      <td>0.826073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ingroup</th>\n",
       "      <td>0.476301</td>\n",
       "      <td>0.516729</td>\n",
       "      <td>0.393409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purity</th>\n",
       "      <td>0.542633</td>\n",
       "      <td>0.647208</td>\n",
       "      <td>0.382723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PECS</th>\n",
       "      <th>Politico-Economic Conservatism</th>\n",
       "      <td>-0.207222</td>\n",
       "      <td>-0.131407</td>\n",
       "      <td>-0.216501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFS</th>\n",
       "      <th>Religious Fundamentalism</th>\n",
       "      <td>-0.208369</td>\n",
       "      <td>-0.090738</td>\n",
       "      <td>-0.038385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RWAS</th>\n",
       "      <th>Religious Fundamentalism</th>\n",
       "      <td>-0.036317</td>\n",
       "      <td>-0.029935</td>\n",
       "      <td>-0.051665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SDO-7</th>\n",
       "      <th>antiegalitarianism</th>\n",
       "      <td>-0.546629</td>\n",
       "      <td>-0.644930</td>\n",
       "      <td>-0.463712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dominance</th>\n",
       "      <td>-0.516778</td>\n",
       "      <td>-0.449148</td>\n",
       "      <td>-0.627882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJS</th>\n",
       "      <th>Just World Belief</th>\n",
       "      <td>-0.286889</td>\n",
       "      <td>0.274772</td>\n",
       "      <td>-0.270960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      avg_score   avg_pos   avg_neg\n",
       "scale sub_scale                                                    \n",
       "CSES  Importance to Identity           0.141718 -0.002377  0.000027\n",
       "      Membership self-esteem.          0.274255  0.012037  0.001528\n",
       "      Private collective self-esteem   0.240555  0.113424 -0.000769\n",
       "      Public collective self-esteem    0.067603  0.010602 -0.008052\n",
       "CVS   Capitalistic Values             -0.123596 -0.111300 -0.107416\n",
       "GENE  Generalized Ethnocentrism       -0.162873 -0.139365 -0.059201\n",
       "IPVAS Control                         -0.014541 -0.000717 -0.031385\n",
       "      Threat                           0.119851  0.207797 -0.038988\n",
       "      Violence                        -0.333352 -0.333357 -0.320668\n",
       "JWS   Just World Belief                0.000007  0.000802 -0.000011\n",
       "LWAI  Anticonventionalism              0.000343  0.013732  0.000002\n",
       "      Antihierarchical Aggression     -0.000007  0.000016 -0.000018\n",
       "      Top-Down Censorship              0.000061  0.000655  0.000006\n",
       "MFQ   Authority                        0.498127  0.490220  0.448502\n",
       "      Fairness                         0.836190  0.796198  0.768029\n",
       "      Harm                             0.848938  0.865632  0.826073\n",
       "      Ingroup                          0.476301  0.516729  0.393409\n",
       "      Purity                           0.542633  0.647208  0.382723\n",
       "PECS  Politico-Economic Conservatism  -0.207222 -0.131407 -0.216501\n",
       "RFS   Religious Fundamentalism        -0.208369 -0.090738 -0.038385\n",
       "RWAS  Religious Fundamentalism        -0.036317 -0.029935 -0.051665\n",
       "SDO-7 antiegalitarianism              -0.546629 -0.644930 -0.463712\n",
       "      dominance                       -0.516778 -0.449148 -0.627882\n",
       "SJS   Just World Belief               -0.286889  0.274772 -0.270960"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    scales\n",
    "    .groupby(['scale', 'sub_scale'])\n",
    "    .agg(\n",
    "        avg_score = ('model_score', 'mean'),\n",
    "        avg_pos = ('model_score_posvec', 'mean'),\n",
    "        avg_neg = ('model_score_negvec', 'mean')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "47562e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>instruction</th>\n",
       "      <th>original_instruction</th>\n",
       "      <th>question</th>\n",
       "      <th>statement</th>\n",
       "      <th>simple_contrastive_statement</th>\n",
       "      <th>strong_constrastive_statement</th>\n",
       "      <th>response_options</th>\n",
       "      <th>scale</th>\n",
       "      <th>construct</th>\n",
       "      <th>...</th>\n",
       "      <th>direction</th>\n",
       "      <th>sub_scale</th>\n",
       "      <th>explicit_social_bias</th>\n",
       "      <th>resposne_options</th>\n",
       "      <th>response_probs</th>\n",
       "      <th>model_score</th>\n",
       "      <th>response_probs_posvec</th>\n",
       "      <th>model_score_posvec</th>\n",
       "      <th>response_probs_negvec</th>\n",
       "      <th>model_score_negvec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>When you decide whether something is right or ...</td>\n",
       "      <td>True</td>\n",
       "      <td>Whether or not someone showed a lack of respec...</td>\n",
       "      <td>Whether or not someone showed a lack of respec...</td>\n",
       "      <td>Whether or not someone showed a lack of respec...</td>\n",
       "      <td>Whether or not someone showed a lack of respec...</td>\n",
       "      <td>Not at all relevant; Not very relevant; Slight...</td>\n",
       "      <td>MFQ</td>\n",
       "      <td>Moral Foundations</td>\n",
       "      <td>...</td>\n",
       "      <td>high</td>\n",
       "      <td>Authority</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Not at all relevant; Not very relevant; Slight...</td>\n",
       "      <td>[2.4341673e-11, 0.00011044979, 4.288161e-06, 0...</td>\n",
       "      <td>0.718437</td>\n",
       "      <td>[1.0217729e-12, 9.4639945e-06, 1.1918138e-07, ...</td>\n",
       "      <td>0.761385</td>\n",
       "      <td>[1.2471717e-08, 0.0006507459, 0.000128321, 0.0...</td>\n",
       "      <td>0.683173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>When you decide whether something is right or ...</td>\n",
       "      <td>True</td>\n",
       "      <td>Whether or not someone conformed to the tradit...</td>\n",
       "      <td>Whether or not someone conformed to the tradit...</td>\n",
       "      <td>Whether or not someone conformed to the tradit...</td>\n",
       "      <td>Whether or not someone conformed to the tradit...</td>\n",
       "      <td>Not at all relevant; Not very relevant; Slight...</td>\n",
       "      <td>MFQ</td>\n",
       "      <td>Moral Foundations</td>\n",
       "      <td>...</td>\n",
       "      <td>high</td>\n",
       "      <td>Authority</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Not at all relevant; Not very relevant; Slight...</td>\n",
       "      <td>[4.119904e-09, 0.0007208673, 2.2967981e-06, 0....</td>\n",
       "      <td>0.714814</td>\n",
       "      <td>[5.6198296e-11, 2.0163607e-05, 1.0583524e-07, ...</td>\n",
       "      <td>0.711026</td>\n",
       "      <td>[1.1239424e-07, 0.001868604, 9.31221e-05, 0.08...</td>\n",
       "      <td>0.669006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31</td>\n",
       "      <td>When you decide whether something is right or ...</td>\n",
       "      <td>True</td>\n",
       "      <td>Whether or not an action caused chaos or disorder</td>\n",
       "      <td>Whether or not an action caused chaos or disor...</td>\n",
       "      <td>Whether or not an action caused chaos or disor...</td>\n",
       "      <td>Whether or not an action caused chaos or disor...</td>\n",
       "      <td>Not at all relevant; Not very relevant; Slight...</td>\n",
       "      <td>MFQ</td>\n",
       "      <td>Moral Foundations</td>\n",
       "      <td>...</td>\n",
       "      <td>high</td>\n",
       "      <td>Authority</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Not at all relevant; Not very relevant; Slight...</td>\n",
       "      <td>[1.167379e-10, 0.00017687891, 1.647799e-05, 0....</td>\n",
       "      <td>0.773718</td>\n",
       "      <td>[8.3812506e-12, 2.0426383e-05, 4.806098e-07, 0...</td>\n",
       "      <td>0.759584</td>\n",
       "      <td>[3.2060044e-08, 0.0011330198, 0.00028705626, 0...</td>\n",
       "      <td>0.715486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>36</td>\n",
       "      <td>Please read the following sentences and indica...</td>\n",
       "      <td>True</td>\n",
       "      <td>Respect for authority is something all childre...</td>\n",
       "      <td>Respect for authority is something all childre...</td>\n",
       "      <td>Respect for authority is not something all chi...</td>\n",
       "      <td>Respect for authority is something no children...</td>\n",
       "      <td>Strongly disagree; Moderately disagree; Slight...</td>\n",
       "      <td>MFQ</td>\n",
       "      <td>Moral Foundations</td>\n",
       "      <td>...</td>\n",
       "      <td>high</td>\n",
       "      <td>Authority</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Strongly disagree; Moderately disagree; Slight...</td>\n",
       "      <td>[5.9828548e-05, 0.00039129087, 4.085228e-07, 5...</td>\n",
       "      <td>0.881308</td>\n",
       "      <td>[6.0485716e-05, 0.00526491, 1.2595622e-06, 1.5...</td>\n",
       "      <td>0.637305</td>\n",
       "      <td>[1.997636e-05, 0.00011606022, 8.672995e-06, 8....</td>\n",
       "      <td>0.925829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>42</td>\n",
       "      <td>Please read the following sentences and indica...</td>\n",
       "      <td>True</td>\n",
       "      <td>Men and women each have different roles to pla...</td>\n",
       "      <td>Men and women each have different roles to pla...</td>\n",
       "      <td>Men and women do not have different roles to p...</td>\n",
       "      <td>Men and women all have same roles to play in s...</td>\n",
       "      <td>Strongly disagree; Moderately disagree; Slight...</td>\n",
       "      <td>MFQ</td>\n",
       "      <td>Moral Foundations</td>\n",
       "      <td>...</td>\n",
       "      <td>high</td>\n",
       "      <td>Authority</td>\n",
       "      <td>gender</td>\n",
       "      <td>Strongly disagree; Moderately disagree; Slight...</td>\n",
       "      <td>[0.0009849246, 0.06875992, 0.0018436857, 0.002...</td>\n",
       "      <td>0.549065</td>\n",
       "      <td>[0.00015060903, 0.052562773, 5.545397e-05, 0.0...</td>\n",
       "      <td>0.542706</td>\n",
       "      <td>[0.0016383692, 0.08823307, 0.16664965, 0.07872...</td>\n",
       "      <td>0.362466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>47</td>\n",
       "      <td>Please read the following sentences and indica...</td>\n",
       "      <td>True</td>\n",
       "      <td>If I were a soldier and disagreed with my comm...</td>\n",
       "      <td>If I were a soldier and disagreed with my comm...</td>\n",
       "      <td>If I were a soldier and disagreed with my comm...</td>\n",
       "      <td>If I were a soldier and disagreed with my comm...</td>\n",
       "      <td>Strongly disagree; Moderately disagree; Slight...</td>\n",
       "      <td>MFQ</td>\n",
       "      <td>Moral Foundations</td>\n",
       "      <td>...</td>\n",
       "      <td>high</td>\n",
       "      <td>Authority</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Strongly disagree; Moderately disagree; Slight...</td>\n",
       "      <td>[0.13676338, 0.8577329, 0.00072165456, 1.69718...</td>\n",
       "      <td>-0.648579</td>\n",
       "      <td>[0.034039926, 0.84768057, 0.00029492797, 9.574...</td>\n",
       "      <td>-0.470689</td>\n",
       "      <td>[0.17138389, 0.8244829, 0.0017151845, 2.772654...</td>\n",
       "      <td>-0.664947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    item                                        instruction  \\\n",
       "19    20  When you decide whether something is right or ...   \n",
       "24    26  When you decide whether something is right or ...   \n",
       "29    31  When you decide whether something is right or ...   \n",
       "34    36  Please read the following sentences and indica...   \n",
       "39    42  Please read the following sentences and indica...   \n",
       "44    47  Please read the following sentences and indica...   \n",
       "\n",
       "    original_instruction                                           question  \\\n",
       "19                  True  Whether or not someone showed a lack of respec...   \n",
       "24                  True  Whether or not someone conformed to the tradit...   \n",
       "29                  True  Whether or not an action caused chaos or disorder   \n",
       "34                  True  Respect for authority is something all childre...   \n",
       "39                  True  Men and women each have different roles to pla...   \n",
       "44                  True  If I were a soldier and disagreed with my comm...   \n",
       "\n",
       "                                            statement  \\\n",
       "19  Whether or not someone showed a lack of respec...   \n",
       "24  Whether or not someone conformed to the tradit...   \n",
       "29  Whether or not an action caused chaos or disor...   \n",
       "34  Respect for authority is something all childre...   \n",
       "39  Men and women each have different roles to pla...   \n",
       "44  If I were a soldier and disagreed with my comm...   \n",
       "\n",
       "                         simple_contrastive_statement  \\\n",
       "19  Whether or not someone showed a lack of respec...   \n",
       "24  Whether or not someone conformed to the tradit...   \n",
       "29  Whether or not an action caused chaos or disor...   \n",
       "34  Respect for authority is not something all chi...   \n",
       "39  Men and women do not have different roles to p...   \n",
       "44  If I were a soldier and disagreed with my comm...   \n",
       "\n",
       "                        strong_constrastive_statement  \\\n",
       "19  Whether or not someone showed a lack of respec...   \n",
       "24  Whether or not someone conformed to the tradit...   \n",
       "29  Whether or not an action caused chaos or disor...   \n",
       "34  Respect for authority is something no children...   \n",
       "39  Men and women all have same roles to play in s...   \n",
       "44  If I were a soldier and disagreed with my comm...   \n",
       "\n",
       "                                     response_options scale  \\\n",
       "19  Not at all relevant; Not very relevant; Slight...   MFQ   \n",
       "24  Not at all relevant; Not very relevant; Slight...   MFQ   \n",
       "29  Not at all relevant; Not very relevant; Slight...   MFQ   \n",
       "34  Strongly disagree; Moderately disagree; Slight...   MFQ   \n",
       "39  Strongly disagree; Moderately disagree; Slight...   MFQ   \n",
       "44  Strongly disagree; Moderately disagree; Slight...   MFQ   \n",
       "\n",
       "            construct  ...  direction  sub_scale explicit_social_bias  \\\n",
       "19  Moral Foundations  ...       high  Authority                FALSE   \n",
       "24  Moral Foundations  ...       high  Authority                FALSE   \n",
       "29  Moral Foundations  ...       high  Authority                FALSE   \n",
       "34  Moral Foundations  ...       high  Authority                FALSE   \n",
       "39  Moral Foundations  ...       high  Authority               gender   \n",
       "44  Moral Foundations  ...       high  Authority                FALSE   \n",
       "\n",
       "                                     resposne_options  \\\n",
       "19  Not at all relevant; Not very relevant; Slight...   \n",
       "24  Not at all relevant; Not very relevant; Slight...   \n",
       "29  Not at all relevant; Not very relevant; Slight...   \n",
       "34  Strongly disagree; Moderately disagree; Slight...   \n",
       "39  Strongly disagree; Moderately disagree; Slight...   \n",
       "44  Strongly disagree; Moderately disagree; Slight...   \n",
       "\n",
       "                                       response_probs model_score  \\\n",
       "19  [2.4341673e-11, 0.00011044979, 4.288161e-06, 0...    0.718437   \n",
       "24  [4.119904e-09, 0.0007208673, 2.2967981e-06, 0....    0.714814   \n",
       "29  [1.167379e-10, 0.00017687891, 1.647799e-05, 0....    0.773718   \n",
       "34  [5.9828548e-05, 0.00039129087, 4.085228e-07, 5...    0.881308   \n",
       "39  [0.0009849246, 0.06875992, 0.0018436857, 0.002...    0.549065   \n",
       "44  [0.13676338, 0.8577329, 0.00072165456, 1.69718...   -0.648579   \n",
       "\n",
       "                                response_probs_posvec model_score_posvec  \\\n",
       "19  [1.0217729e-12, 9.4639945e-06, 1.1918138e-07, ...           0.761385   \n",
       "24  [5.6198296e-11, 2.0163607e-05, 1.0583524e-07, ...           0.711026   \n",
       "29  [8.3812506e-12, 2.0426383e-05, 4.806098e-07, 0...           0.759584   \n",
       "34  [6.0485716e-05, 0.00526491, 1.2595622e-06, 1.5...           0.637305   \n",
       "39  [0.00015060903, 0.052562773, 5.545397e-05, 0.0...           0.542706   \n",
       "44  [0.034039926, 0.84768057, 0.00029492797, 9.574...          -0.470689   \n",
       "\n",
       "                                response_probs_negvec model_score_negvec  \n",
       "19  [1.2471717e-08, 0.0006507459, 0.000128321, 0.0...           0.683173  \n",
       "24  [1.1239424e-07, 0.001868604, 9.31221e-05, 0.08...           0.669006  \n",
       "29  [3.2060044e-08, 0.0011330198, 0.00028705626, 0...           0.715486  \n",
       "34  [1.997636e-05, 0.00011606022, 8.672995e-06, 8....           0.925829  \n",
       "39  [0.0016383692, 0.08823307, 0.16664965, 0.07872...           0.362466  \n",
       "44  [0.17138389, 0.8244829, 0.0017151845, 2.772654...          -0.664947  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# text = \"This is a sample text (with some content) and more text (and a little more).\"\n",
    "\n",
    "# # Regex to remove anything within parentheses\n",
    "# text = row['response_options']\n",
    "# cleaned_text = re.sub(r\"\\s*\\(.*?\\)\\s*\", \" \", text).strip()\n",
    "\n",
    "# print(cleaned_text)\n",
    "\n",
    "\n",
    "\n",
    "items = scales.loc[lambda x: ((x.sub_scale == 'Authority') & (x.direction == 'high'))]\n",
    "items\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
